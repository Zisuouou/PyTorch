{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e79c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SVT\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80966b",
   "metadata": {},
   "source": [
    "- 데이터셋 불러오기\n",
    "    - root = 학습/테스트 데이터 저장 경로\n",
    "    - train = 학습용 또는 테스트용 데이터셋 여부 지정\n",
    "    - download=True : root에 데이터가 없는 경우 인터넷에서 다운로드\n",
    "    - transform 과 target_transform은 특징(feature)과 정답(label) 변형(transform) 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1687c001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26422272it [01:19, 333472.84it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 109139.51it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4422656it [00:03, 1301682.69it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6144it [00:00, ?it/s]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3860a",
   "metadata": {},
   "source": [
    "- 파일에서 사용자 정의 데이터셋 만들기\n",
    "    - ashionMNIST 이미지들은 img_dir 디렉토리에 저장되고, 정답은 annotations_file csv 파일에 별도로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78985a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ea4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):       # Dataset 객체 생성 시 한 번만 실행\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = target_transform\n",
    "\n",
    "    def __len__(self):      # 데이터셋 샘플 개수 반환\n",
    "        return len(self.img_labels)\n",
    "  \n",
    "    def __getitem__(self, idx):     # 주어진 인덱스 idx에 해당하는 샘플을 데이터셋에 불러오고 반환\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label    \n",
    "    # 인덱스를 기반으로 디스크에서 이미지 위치 식별 후 read_image를 사용하여 이미지 텐서로 변환\n",
    "    # self.img_labels의 csv데이터로부터 해당하는 정답(label)을 가져오고, 변환(transform)함수들은 직접 호출한 뒤,\n",
    "    # 텐서 이미지와 라벨을 Python 사전(dict)형으로 반환  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df81612",
   "metadata": {},
   "source": [
    "- DataLoader로 학습용 데이터 준비\n",
    "    - Dataset 은 데이터셋의 특징(feature)을 가져오고 하나의 샘플에 정답(label)을 지정하는 일을 한 번에 함\n",
    "    - 모델을 학습할 때, 일반적으로 샘플ㄷ르을 미니배치로 전달하고 매 에포크마다 데이터를 다시 섞어서 과적합을 막고(overfit),\n",
    "    - Python의 multiprocessiong 을 사용하여 데이터 검색 속도를 높이려 함\n",
    "    - DataLoader는 간단한 API로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체(iterabel)임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6b469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trian_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a5d58",
   "metadata": {},
   "source": [
    "1. 신경망 모델 구성하기\n",
    "    - FashionMNIST 데이터셋의 이미지들을 분류하는 신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da78b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f80565",
   "metadata": {},
   "source": [
    "- 학습을 위한 장치 \n",
    "    - torch.cuda 사용 가능하면 GPU, 그렇지 않으면 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9eb89ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d92426",
   "metadata": {},
   "source": [
    "- 클래스 정의하기\n",
    "    - 신경망 모델을 nn.Module의 하위클래스로 정의,\n",
    "    - __init__에서 신경망 계층 초기화\n",
    "    - nn.Module을 상속받은 모든 클래스는 forward 메소드에서 입력 데이터에 대한 연산 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300110ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7367082",
   "metadata": {},
   "source": [
    "- nn.Module\n",
    "    - PyTorch의 nn라이브러리는 Neural Network의 모든 것을 포괄하는 모든 신경망 모델의 Base Class\n",
    "    - nn.Module을 상속한 subclass가 신경망 모델로 사용되기 위해서는 앞서 소개한 두 메서드를 override해야함\n",
    "- \\__init__\\(self): 내가 사용하고 싶은, 내 신경망 모델에 사용될 요소들을 정의 및 초기화 하는 메서드\n",
    "- forward(self, x): __init__에서 정의된 구성품들을 연결하는 메서드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f9e62",
   "metadata": {},
   "source": [
    "2. 모델 매개변수 최적화 하기\n",
    "    - 에프크라고 부르는 각 반복단계에서 모델 출력을 추측하고, 추측과 정답 사이의 오류(손실)을 계산하고, 매개변수에 대한 오류의 도함수를 수집한 뒤, 경사하강법을 사용하여 파라미터들을 최적화 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9561537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1775ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "trian_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2128b",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터 : 모델 최적화 과정을 제어할 수 있는 조절 가능한 매개변수\n",
    "    - 에포크 수 : 데이터셋을 반복하는 횟수\n",
    "    - 배치크기 : 매개변수가 갱신되기 전 신경망을 통해 전파된 데이터 샘플의 수 \n",
    "    - 학습률 : 각 배치/에포크에서 모델의 매개변수를 조절하는 비율로, 값이 작을수록 학습 속도가 느려지고, 값이 커지면 학습 중 예측할 수 없는 동작 발생\n",
    "\n",
    "- 최적화 단계(Optimization Loop) : 하이퍼파라미터를 설정한 뒤, 최적화 단계를 통해 모델을 학습하고 최적화할 수 있음, 최적화 단계의 각 반복(iteration)을 에포크라고 부름, 하나의 에폭은 두 부부으로 구성됨\n",
    "    - 학습 단계(train_ loop) : 학습용 데이터셋을 반복하고 최적의 매개변수로 수렴\n",
    "    - 검증/테스트 단계(validation/test loop) : 모델 성능이 개선되고 있는지를 확인하기 위해 테스트 데이터셋 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914aaff2",
   "metadata": {},
   "source": [
    "- 손실 함수(loss function)\n",
    "    - 일반적인 손심함수에는 회귀 문제에 사용하는 nn.MSELoss 나 분류에 사용하는 nn.NLLLoss, nn.CrossEntropyLoss등이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f93987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 초기화\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d1ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 하이퍼파라미터 정의\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 옵티마이저 : 학습하려는 모델의 매개변수와 학습률 하이퍼파라미터를 등록하여 옵티마이저 초기화\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f55b7",
   "metadata": {},
   "source": [
    "- 학습 단계(loop) 에서 최적화는 세 단계로 이루어진다\n",
    "    - optimizer.zero_grad()를 호출하여 모델 매개변수의 변화도를 재설정\n",
    "    - 기본적으로 변화도는 더해지기 때문에 중복 계산을 막기 위해 반복할 때마다 명시적으로 0으로 설정\n",
    "\n",
    "    - loss.backward()를 호출하여 예측선실을 역전파, PyTorch는 각 매개변수에 대한 손실의 변화도를 저장\n",
    "    - 변화도를 계산한 뒤에는 optimizer.step()을 호출하여 역전파 단계에서 수집된 변화도로 매개변수 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89549bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 구현\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 예측과 손실 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 ==0:\n",
    "            loss, current = loss.item(), batch + len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Aug loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e075ddd",
   "metadata": {},
   "source": [
    "- 손실함수와 옵티마이저를 초기화하고 train_loop 와 test_loop 에 전달함\n",
    "- 모델의 성능 향상을 알아보기 위해 자유롭게 에폭 수를 증가시켜 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15d3e30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "loss: 2.303689 [   64/60000]\n",
      "loss: 2.296791 [  164/60000]\n",
      "loss: 2.288880 [  264/60000]\n",
      "loss: 2.293881 [  364/60000]\n",
      "loss: 2.270637 [  464/60000]\n",
      "loss: 2.260277 [  564/60000]\n",
      "loss: 2.267838 [  664/60000]\n",
      "loss: 2.249465 [  764/60000]\n",
      "loss: 2.263236 [  864/60000]\n",
      "loss: 2.242618 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Aug loss: 2.235273 \n",
      "\n",
      "Epoch 2\n",
      "-----------------------\n",
      "loss: 2.241686 [   64/60000]\n",
      "loss: 2.230864 [  164/60000]\n",
      "loss: 2.214506 [  264/60000]\n",
      "loss: 2.241886 [  364/60000]\n",
      "loss: 2.181225 [  464/60000]\n",
      "loss: 2.157978 [  564/60000]\n",
      "loss: 2.202582 [  664/60000]\n",
      "loss: 2.153542 [  764/60000]\n",
      "loss: 2.190974 [  864/60000]\n",
      "loss: 2.145562 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.2%, Aug loss: 2.128056 \n",
      "\n",
      "Epoch 3\n",
      "-----------------------\n",
      "loss: 2.138322 [   64/60000]\n",
      "loss: 2.113633 [  164/60000]\n",
      "loss: 2.064516 [  264/60000]\n",
      "loss: 2.129838 [  364/60000]\n",
      "loss: 2.016926 [  464/60000]\n",
      "loss: 1.955399 [  564/60000]\n",
      "loss: 2.047356 [  664/60000]\n",
      "loss: 1.942666 [  764/60000]\n",
      "loss: 2.002047 [  864/60000]\n",
      "loss: 1.927781 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Aug loss: 1.917314 \n",
      "\n",
      "Epoch 4\n",
      "-----------------------\n",
      "loss: 1.924007 [   64/60000]\n",
      "loss: 1.888228 [  164/60000]\n",
      "loss: 1.811942 [  264/60000]\n",
      "loss: 1.940518 [  364/60000]\n",
      "loss: 1.794832 [  464/60000]\n",
      "loss: 1.697955 [  564/60000]\n",
      "loss: 1.838884 [  664/60000]\n",
      "loss: 1.699172 [  764/60000]\n",
      "loss: 1.790796 [  864/60000]\n",
      "loss: 1.692066 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Aug loss: 1.700316 \n",
      "\n",
      "Epoch 5\n",
      "-----------------------\n",
      "loss: 1.699043 [   64/60000]\n",
      "loss: 1.664978 [  164/60000]\n",
      "loss: 1.571784 [  264/60000]\n",
      "loss: 1.747193 [  364/60000]\n",
      "loss: 1.597406 [  464/60000]\n",
      "loss: 1.482568 [  564/60000]\n",
      "loss: 1.633177 [  664/60000]\n",
      "loss: 1.499008 [  764/60000]\n",
      "loss: 1.564206 [  864/60000]\n",
      "loss: 1.482169 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Aug loss: 1.495440 \n",
      "\n",
      "Epoch 6\n",
      "-----------------------\n",
      "loss: 1.465330 [   64/60000]\n",
      "loss: 1.456123 [  164/60000]\n",
      "loss: 1.345011 [  264/60000]\n",
      "loss: 1.574117 [  364/60000]\n",
      "loss: 1.381962 [  464/60000]\n",
      "loss: 1.306751 [  564/60000]\n",
      "loss: 1.458630 [  664/60000]\n",
      "loss: 1.347885 [  764/60000]\n",
      "loss: 1.380665 [  864/60000]\n",
      "loss: 1.332989 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Aug loss: 1.339492 \n",
      "\n",
      "Epoch 7\n",
      "-----------------------\n",
      "loss: 1.284777 [   64/60000]\n",
      "loss: 1.304894 [  164/60000]\n",
      "loss: 1.180268 [  264/60000]\n",
      "loss: 1.450666 [  364/60000]\n",
      "loss: 1.231210 [  464/60000]\n",
      "loss: 1.182702 [  564/60000]\n",
      "loss: 1.342361 [  664/60000]\n",
      "loss: 1.247174 [  764/60000]\n",
      "loss: 1.262765 [  864/60000]\n",
      "loss: 1.238692 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Aug loss: 1.235322 \n",
      "\n",
      "Epoch 8\n",
      "-----------------------\n",
      "loss: 1.166347 [   64/60000]\n",
      "loss: 1.208193 [  164/60000]\n",
      "loss: 1.069600 [  264/60000]\n",
      "loss: 1.367056 [  364/60000]\n",
      "loss: 1.139078 [  464/60000]\n",
      "loss: 1.098293 [  564/60000]\n",
      "loss: 1.267503 [  664/60000]\n",
      "loss: 1.179135 [  764/60000]\n",
      "loss: 1.187225 [  864/60000]\n",
      "loss: 1.178298 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Aug loss: 1.165702 \n",
      "\n",
      "Epoch 9\n",
      "-----------------------\n",
      "loss: 1.085491 [   64/60000]\n",
      "loss: 1.143795 [  164/60000]\n",
      "loss: 0.993022 [  264/60000]\n",
      "loss: 1.310552 [  364/60000]\n",
      "loss: 1.080291 [  464/60000]\n",
      "loss: 1.038262 [  564/60000]\n",
      "loss: 1.216732 [  664/60000]\n",
      "loss: 1.131020 [  764/60000]\n",
      "loss: 1.133413 [  864/60000]\n",
      "loss: 1.136330 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Aug loss: 1.115809 \n",
      "\n",
      "Epoch 10\n",
      "-----------------------\n",
      "loss: 1.024264 [   64/60000]\n",
      "loss: 1.097473 [  164/60000]\n",
      "loss: 0.935561 [  264/60000]\n",
      "loss: 1.268446 [  364/60000]\n",
      "loss: 1.038082 [  464/60000]\n",
      "loss: 0.992185 [  564/60000]\n",
      "loss: 1.178724 [  664/60000]\n",
      "loss: 1.094154 [  764/60000]\n",
      "loss: 1.090720 [  864/60000]\n",
      "loss: 1.104550 [  964/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Aug loss: 1.076816 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------\")\n",
    "    train_loop(trian_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802f16a",
   "metadata": {},
   "source": [
    "3. 모델 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f16a2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43cbe7",
   "metadata": {},
   "source": [
    "- 모델 가중치 저장하고 불러오기\n",
    "    - PyTorch 모델은 학습한 매개변수를 state_dict라고 불리는 내부 상태 사전(internal state dictionary)에 저장함\n",
    "    - 이 상태 값들은 torch.save 메서드를 사용하여 저장(persist)함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3108f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\SVT/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:47<00:00, 11.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c499ec",
   "metadata": {},
   "source": [
    "- 모델 가중치를 불러오기 위해선, 먼저 동일한 모델의 인스턴스를 생성한 다음\n",
    "- load_state_dict() 메서드를 사용하여 매개변수 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b21a4022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # 기본 가중치를 불러오지 않으므로 pretrained=True를 지정하지 않음\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a7305",
   "metadata": {},
   "source": [
    "- 모델의 형태를 포함하여 저장하고 불러오기\n",
    "    - 모델의 가중치를 불러올 때, 신경망의 구조를 정의하기 위해 모델의 클래스를 먼저 생성해야했음\n",
    "    - 이 클래스의 구조를 모델과 함께 저장하고 싶으면, (model.state_dict()가 아닌) model을 저장 함수에 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d71f6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9546bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd8c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
