{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20754349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SVT\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e55ca9",
   "metadata": {},
   "source": [
    "- 텐서 생성 및 변환\n",
    "    - 텐서는 파이토치의 가장 기본이 되는 데이터 구조\n",
    "    - numpy 의 다차원배열과 비슷하며 GPU에서도 연산 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa011226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "CUDA available: True\n",
      "CUDA version: 11.3\n",
      "cuDNN version: 8200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a9523f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2차원 텐서 생성\n",
    "torch.tensor([[1,2],\n",
    "              [3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769a5541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU가 있다면\n",
    "torch.tensor([[1,2],\n",
    "              [3,4]], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bd0bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU가 있다면 GPU상의 텐서를 GPU의 텐서로 변환 후 ndarray로 변환\n",
    "temp = torch.tensor([[1,2], [3,4]], device = \"cuda:0\")\n",
    "temp.to(\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c232358d",
   "metadata": {},
   "source": [
    "- 텐서를 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bae40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.tensor([[1,2], [3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1fa51db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ndarray로 변환\n",
    "temp.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ec47bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpu가 있다면 gpu상의 텐서를 cpu의 텐서로 변환한 후 ndarray로 변환\n",
    "temp = torch.tensor([[1, 2], [3, 4]], device = \"cuda:0\")\n",
    "temp.to(\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eadd18",
   "metadata": {},
   "source": [
    "- 텐서의 인덱스 조작\n",
    "    - 텐서는 넘파이의 다치원배열과 유사하게 동작하기 때문에 배열처럼 인덱스를 바로 지정하거나 슬라이스 등을 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cebf79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치로 1차원 벡터 생성\n",
    "temp = torch.FloatTensor([1,2,3,4,5,6,7])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acbd1bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(2.), tensor(3.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스로 접근\n",
    "temp[0], temp[1], temp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e2c7205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 4., 5.]), tensor([1., 3., 5., 7.]), tensor([5., 6.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 슬라이스로 접근\n",
    "temp[2:5], temp[::2], temp[4:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf79aac",
   "metadata": {},
   "source": [
    "- 텐서 연산\n",
    "    - 텐서는 넘파이의 다차원배열처럼 다양한 수학 연산이 가능하며, gpu를 사용하면 더 빨리 연산할 수 있음\n",
    "    - 단, 텐서 간의 타입이 다르면 연산 불가\n",
    "        - 예) FloatTensor(32비트의 부등 소수점)와 DoubleTensor(64비트의 부등 소수점) 간에 사칙 연산을 수행하면 오류 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32bcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이가 3인 벡터 생성\n",
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32dc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 길이가 같은 벡터 간 뺄셈 연산\n",
    "print(w - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7324bbf",
   "metadata": {},
   "source": [
    "- 텐서의 차원 조작\n",
    "    - 텐서의 차원을 변경하는 명령어\n",
    "        - view: 넘파이의 reshape와 유사\n",
    "        - cat: 다른 길이의 텐서를 하나로 병합\n",
    "        - transpose: 행렬의 전치 또는 차원의 순서 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5718d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 x 2 행렬 생성\n",
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e30f0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6b09719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 x 2 행렬을 4 x 1 행렬로 변환\n",
    "temp.view(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f73f77f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2x2 행렬을 1차원 벡터로 변형\n",
    "temp.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68e610",
   "metadata": {},
   "source": [
    "- -1 은 다른 차원으로부터 해당 값을 유추하겠다느 뜻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b87f7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e72ba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0528bd",
   "metadata": {},
   "source": [
    "- 데이터로더\n",
    "    - torch.utils.data.DataLoader 는 학습에 사용될 데이터 전체를 보관했다가 모델 학습을 할 때 배치 크기만큼 데이터를 꺼내서 사용\n",
    "    - 주의할 점은 미리 데이터를 잘라 놓는 것이 아니라 내부적으로 이터레이터에 포함된 인덱스를 이용하여 배치 크기만큼 데이터 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165a493",
   "metadata": {},
   "source": [
    "- 파이토치 데이터셋 사용\n",
    "    - torchvision 은 파이토치에서 제공하는 데이터셋이 모여있는 패키지\n",
    "    - 파이토치 데이터셋을 다운로드 받으려면 requests 라이브러리 설치 필요\n",
    "        - HTTP 요청을 하기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f7fe36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a341f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균이 0.5, 표준편차가 1.0이 되도록 데이터의 분포를 정규화\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cb1fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"./data/MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b25fbc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:03, 2819799.26it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 165775.44it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:01, 1278489.87it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 5121592.29it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data/MNIST\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MNIST(datapath, transform = mnist_transform, train = True, download= True)\n",
    "test_dataset = MNIST(datapath, transform = mnist_transform, train = False, download= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0692556f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "932c45ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: 60000\n",
      "테스트 데이터 크기: 10000\n",
      "샘플 이미지 크기: torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 확인용 코드\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./data\", train = True, download=False, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(root=\"./data\", train = False, download=False, transform=transforms.ToTensor())\n",
    "\n",
    "print(\"훈련 데이터 크기:\", len(mnist_train))\n",
    "print(\"테스트 데이터 크기:\", len(mnist_test))\n",
    "print(\"샘플 이미지 크기:\", mnist_train[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5d0f4",
   "metadata": {},
   "source": [
    "- 모델 정의\n",
    "    - 파이토치에서 모델을 정의하기 위해서는 Module 을 상속한 클래스를 사용\n",
    "        - layer : 모듈 또는 모듈을 구성하는 한 개의 계층\n",
    "            - 예) 합성곱창, 선형계층 등\n",
    "        - module : 한 개 이상의 계층이 모여서 구성된 것, 모듈이 모여 새로운 모듈을 만들 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b30682",
   "metadata": {},
   "source": [
    "- nn.Module()을 상속하여 정의하는 방법\n",
    "    - 파이토치에서 nn.Module을 상속받는 모델은 기본적으로 __init__() 과 forward() 함수를 포함\n",
    "        - __init__() 에서는 모델에서 사용될 모듈, 활성화 함수 등을 정의\n",
    "        - forward() 함수에서는 모델에서 실행되어야 하는 연산을 정의\n",
    "    - nn.Sequential을 사용하면 __init__() 에서 사용할 네트워크 모델들을 정의해 줄 뿐만 아니라 forward() 함수의 모델에서 실행되어야 할 계산을 좀 더 가독성이 뛰어나게 코드로 작성할 수 있음\n",
    "\n",
    "    - 또한, Sequential 객체에는 그 안에 포함된 각 모듈을 순차적으로 실행해 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26a1ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 부모 클래스의 생성자 먼저 실행해주고 자식 클래스 생성자 실행\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),   # 활성화 함수\n",
    "            # input으로 들어온 값 자체를 수정, 메모리 효율이 좋아지지만 input 값이 사라짐\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.layer3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489616ee",
   "metadata": {},
   "source": [
    "- __init__ : 생성자\n",
    "- Conv2D : 2차원 형식, in_channels : 입력되는 채널, out_channels : 출력되는 채널, kernel_size : 가로 세로 크기 5\n",
    "- bias : Y절편 쓰냐 안쓰냐\n",
    "- 저 Linear가 Dense층이랑 같은 전결합층, dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15ed7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 생성\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "255aae7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       " )]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구성 노드를 반환\n",
    "list(model.children())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca630f",
   "metadata": {},
   "source": [
    "- dilation : 커널 사이의 간격\n",
    "- ceil_mode : 값의 올림처리(False), 내림처리(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a1aa8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MLP(\n",
       "   (layer1): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ),\n",
       " Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=750, out_features=10, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       " ),\n",
       " Linear(in_features=750, out_features=10, bias=True),\n",
       " ReLU(inplace=True)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 네트워크에 대한 모든 노드를 반환\n",
    "list(model.modules())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd0e17",
   "metadata": {},
   "source": [
    "- 함수로 신경망 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4f7ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(in_features = 1, hidden_features = 20, out_features = 1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c19eeb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(in_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa898517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefd09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de6b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740295b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7d1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d744751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c478329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3358e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e810d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26eb4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
